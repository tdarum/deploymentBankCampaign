{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imporrt libarary \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import google cloud library\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "# from google.cloud import aiplatform\n",
    "# from support_functions import missing_value, fill_missing, list_dtypes\n",
    "\n",
    "## sklearn module\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"trial_bigq.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'dtidsUS'\n",
    "dataset_id = 'capstone'\n",
    "table_id = 'german_dataset'\n",
    "region = 'us-central1'\n",
    "bucket_name = 'modul4'\n",
    "blob_name = 'ilham/german_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project='dtidsus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model succeeded\n"
     ]
    }
   ],
   "source": [
    "try : \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name) # Add bucket name\n",
    "    data_capstone = bucket.blob('ilham/german_dataset.csv')\n",
    "    data_capstone.upload_from_filename('german_dataset.csv')\n",
    "\n",
    "    print (\"Uploading model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client('dtidsUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(f\"\"\"select * from {dataset_id}.{table_id}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbcbx\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>married</td>\n",
       "      <td>Univ</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>131895</td>\n",
       "      <td>132154</td>\n",
       "      <td>129237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "      <td>married</td>\n",
       "      <td>Univ</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>56626</td>\n",
       "      <td>58512</td>\n",
       "      <td>61926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40000</td>\n",
       "      <td>married</td>\n",
       "      <td>Univ</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>12961</td>\n",
       "      <td>12029</td>\n",
       "      <td>11738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000</td>\n",
       "      <td>single</td>\n",
       "      <td>Univ</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>28949</td>\n",
       "      <td>30319</td>\n",
       "      <td>29400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>married</td>\n",
       "      <td>Univ</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL MARRIAGE EDUCATION   SEX  AGE  BILL_AMT1  BILL_AMT2  BILL_AMT3  \\\n",
       "0      50000  married      Univ  male   23     131895     132154     129237   \n",
       "1      50000  married      Univ  male   24      56626      58512      61926   \n",
       "2      40000  married      Univ  male   25      12961      12029      11738   \n",
       "3      30000   single      Univ  male   26      28949      30319      29400   \n",
       "4      30000  married      Univ  male   26          0          0          0   \n",
       "\n",
       "   TARGET  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#cleansing \n",
    "result = df.drop(['ID'], axis = 1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL    0\n",
       "MARRIAGE     4\n",
       "EDUCATION    0\n",
       "SEX          0\n",
       "AGE          4\n",
       "BILL_AMT1    0\n",
       "BILL_AMT2    0\n",
       "BILL_AMT3    0\n",
       "TARGET       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.76      0.72      1980\n",
      "         1.0       0.58      0.48      0.52      1344\n",
      "\n",
      "    accuracy                           0.65      3324\n",
      "   macro avg       0.63      0.62      0.62      3324\n",
      "weighted avg       0.64      0.65      0.64      3324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbcbx\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = result.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a dictionary to store label encoders for each column\n",
    "encoders = {}\n",
    "\n",
    "# Iterate through categorical columns\n",
    "for col in categorical_cols:\n",
    "    # Create a LabelEncoder object for each column\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Fit and transform the column\n",
    "    result[col] = encoder.fit_transform(result[col])\n",
    "\n",
    "    # Store the encoder in the dictionary for later use\n",
    "    encoders[col] = encoder\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "y = result['TARGET']  \n",
    "X = result.drop(['TARGET'], axis=1)  \n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Save Model\n",
    "model_filename = \"model.pkl\"\n",
    "pickle.dump(model, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model succeeded\n"
     ]
    }
   ],
   "source": [
    "try : \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name) # Add bucket name\n",
    "    blob_model = bucket.blob('ilham/model/model.pkl')\n",
    "    blob_model.upload_from_filename('model.pkl')\n",
    "\n",
    "    print (\"Uploading model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"dev_trial.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/41965541199/locations/us-central1/models/4379281146152747008/operations/8350858329844613120\n",
      "Model created. Resource name: projects/41965541199/locations/us-central1/models/4379281146152747008@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/41965541199/locations/us-central1/models/4379281146152747008@1')\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project='dtidsus', location='us-central1')\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name='jaya_model_000',\n",
    "    artifact_uri=\"gs://modul4/ilham/model/\",\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest\",\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/41965541199/locations/us-central1/endpoints/2241324766407426048/operations/8402649725559373824\n",
      "Endpoint created. Resource name: projects/41965541199/locations/us-central1/endpoints/2241324766407426048\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/41965541199/locations/us-central1/endpoints/2241324766407426048')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=\"jaya-endpoint-000\",\n",
    "    project='dtidsus',\n",
    "    location='us-central1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_replica_count: int = 1\n",
    "max_replica_count: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Model projects/41965541199/locations/us-central1/models/4379281146152747008 to Endpoint : projects/41965541199/locations/us-central1/endpoints/2241324766407426048\n",
      "Deploy Endpoint model backing LRO: projects/41965541199/locations/us-central1/endpoints/2241324766407426048/operations/54664866274738176\n",
      "Endpoint model deployed. Resource name: projects/41965541199/locations/us-central1/endpoints/2241324766407426048\n"
     ]
    }
   ],
   "source": [
    "endpoint.deploy( \n",
    "    model=model,\n",
    "    deployed_model_display_name='jaya_model_000',\n",
    "    machine_type='e2-standard-2',\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    sync=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#using endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict your data with online prediction here \n",
    "PROJECT_ID = 'dtidsus'\n",
    "ENDPOINT_ID = \"projects/41965541199/locations/us-central1/endpoints/2241324766407426048\"\n",
    "REGION = 'us-central1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION: Prediction(predictions=[0.0], deployed_model_id='6724688981780332544', metadata=None, model_version_id='1', model_resource_name='projects/41965541199/locations/us-central1/models/4379281146152747008', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "endpoint = aiplatform.Endpoint(ENDPOINT_ID)\n",
    "prediction = endpoint.predict(instances=[[50000, 1, 3, 1, 23, 131895, 132154, 129237]])\n",
    "\n",
    "print(\"PREDICTION:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#manual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download model succeeded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob_model = bucket.blob('ilham/model/model.pkl')\n",
    "    blob_model.download_to_filename('model_new.pkl')\n",
    "\n",
    "    print (\"download model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = pickle.load(open('model_new.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
